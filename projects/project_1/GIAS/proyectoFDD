#! /bin/bash

# Default parameter setup with fallbacks
# $1: Database name (default: fdd2db)
# $2: User name (default: current user)
# $3: N, number of elements (default: 10)
# $4: M, number of user/cart entries (default: 1000)
# $5: Password (default: memo)
# $6: Port number (default: 6666)
database=${1:-fdd2db}
user=${2:-$(whoami)}
N=${3:-10}
M=${4:-1000}
pass=${5:-memo}
port=${6:-6666}

# Display the database and user information being used
echo "Working with database: $database | user: $user"

# Arrays containing names of tables and views
tables=('carts_books', 'bookalog', 'catalog', 'carts', 'u_table')
views=('result')

# Loop to drop existing views
for view in ${views[@]}
do
    echo "Dropping views $view"
    psql -d $database -U $user -c "drop view if exists $view cascade"
done

# Loop to drop existing tables
for table in ${tables[@]}
 do
	echo "Dropping table $table"
	psql -d $database -U $user -c "drop table if exists $table cascade"
done

# Creating the 'catalog' table
echo "Creating table bookshelfs"
psql -d $database -c "create table if not exists catalog(bookshelf_id serial primary key, title varchar(100), url varchar(200))"

# Populating the 'catalog' table
echo "Populating table catalog"
# The following line is commented out; it's an alternative way to get bookshelf data
# curl https://www.gutenberg.org/ebooks/bookshelf/
cat books.txt | grep '"/ebooks/bookshelf/[0-9]' | awk -F '"' '{print "https://www.gutenberg.org"$2";",$4}'| sed -E "s/'/''/g" | awk 'BEGIN { FS = "; " } {print "insert into catalog (title, url) values (\x27"$2"\x27, \x27"$1"\x27);"}'> prueba.txt
psql -d $database -f prueba.txt

# Getting the maximum count from the 'catalog' table
max_N=$(psql -tA $database -c "select count(*) from catalog")

echo $N

# Conditional checks on provided parameters
if [[ $N -le $max_N ]] && [[ $N -ge 1 ]] && [[ $M -le 10000 ]] && [[ $M -ge 1 ]]
then
   echo "Generating a sample of $N elements"
   # Fetch a random sample of URLs from the 'catalog' table
   tot_urls=($(psql -tA $database -c "select url from catalog order by RANDOM() limit $N"))

   # Creating and populating 'bookalog' table with book data
   echo "Creating table books"
   psql -d $database -c "create table if not exists bookalog(book_id serial primary key, bookshelf_id integer references catalog(bookshelf_id), title varchar(500), author varchar(300),  url varchar(300), downloads integer)"
   for i in ${tot_urls[@]}
   do
       echo $i
       # Fetch bookshelf ID for the current URL
       shelf=$(psql -tA $database -c "select bookshelf_id from catalog where url='$i'")
       echo $shelf
       # Process and insert book data into 'bookalog' table
       # Several `sed` and `awk` commands are used to format and prepare SQL insert statements
       curl $i | [Data Processing Commands]
       psql -d $database -f prueba4.txt       
   done
   
   # Creating a view named 'result'
   psql -d $database -c "create or replace view result as (select *, NTILE(100) over(order by downloads) as percentile from bookalog)"

   # Creating 'users', 'carts', and 'carts_books' tables
   echo "Creating table users"
   psql -d $database -c "create table if not exists u_table(user_id serial primary key, name varchar(200))"
   echo "Creating table carts"
   psql -d $database -c "create table if not exists carts(cart_id serial primary key, user_id integer references u_table(user_id), purchase_date date)"
   echo "Creating table n-m carts_books"
   psql -d $database -c "create table if not exists carts_books(cart_id integer references carts(cart_id), book_id integer references bookalog(book_id), constraint pk_cart_book primary key (cart_id, book_id))"

   # Populating 'users', 'carts', and 'carts_books' tables
   for i in $(seq $M)
   do
       [User and Cart Data Generation and Insertion Commands]
   done

   # Running Python script for data analysis and visualization
   ipython -c "[Python Data Analysis Script]"
   
else
   echo "ERROR"
   echo "Selected N is out of bounds"
fi

# Optional and debugging commands (currently commented out)
# [Optional Commands for Individual Table Population and Debugging]

